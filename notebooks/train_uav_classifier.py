{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:07:21.744650Z\",\"iopub.execute_input\":\"2025-09-25T17:07:21.745252Z\",\"iopub.status.idle\":\"2025-09-25T17:07:21.749533Z\",\"shell.execute_reply.started\":\"2025-09-25T17:07:21.745223Z\",\"shell.execute_reply\":\"2025-09-25T17:07:21.748775Z\"}}\n## Deep Learning Model - Image Classifier\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:07:21.756418Z\",\"iopub.execute_input\":\"2025-09-25T17:07:21.756650Z\",\"iopub.status.idle\":\"2025-09-25T17:07:21.778477Z\",\"shell.execute_reply.started\":\"2025-09-25T17:07:21.756632Z\",\"shell.execute_reply\":\"2025-09-25T17:07:21.777599Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# Check for internet connectivity \nimport socket\ntry:\n    socket.setdefaulttimeout(1)\n    socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(('1.1.1.1', 53))\nexcept socket.error:\n    raise Exception(\"No internet. Enable your internet connection.\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:07:21.779867Z\",\"iopub.execute_input\":\"2025-09-25T17:07:21.780110Z\",\"iopub.status.idle\":\"2025-09-25T17:08:51.268232Z\",\"shell.execute_reply.started\":\"2025-09-25T17:07:21.780089Z\",\"shell.execute_reply\":\"2025-09-25T17:08:51.267551Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# Install dependencies if running on Kaggle \nimport os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif iskaggle:\n    !pip install -Uqq fastai icrawler --use-deprecated=legacy-resolver\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:08:51.269144Z\",\"iopub.execute_input\":\"2025-09-25T17:08:51.269401Z\",\"iopub.status.idle\":\"2025-09-25T17:09:03.768954Z\",\"shell.execute_reply.started\":\"2025-09-25T17:08:51.269372Z\",\"shell.execute_reply\":\"2025-09-25T17:09:03.768403Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# Import libraries \nfrom fastai.vision.all import *\nfrom PIL import Image\nfrom pathlib import Path\nfrom time import sleep\nimport shutil\nfrom icrawler import ImageDownloader\nfrom icrawler.builtin import GoogleImageCrawler\nfrom icrawler.builtin.google import GoogleFeeder, GoogleParser\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:09:03.770327Z\",\"iopub.execute_input\":\"2025-09-25T17:09:03.770780Z\",\"iopub.status.idle\":\"2025-09-25T17:09:03.775703Z\",\"shell.execute_reply.started\":\"2025-09-25T17:09:03.770760Z\",\"shell.execute_reply\":\"2025-09-25T17:09:03.774978Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# Define custom downloader and crawler for Google images \nclass MyDownloader(ImageDownloader):\n    def get_filename(self, task, default_ext):\n        filename = super().get_filename(task, default_ext).split(\".\")[0]\n        return self.prefix + filename + \".png\"\n\nclass MyCrawler(GoogleImageCrawler):\n    def __init__(self, feeder_cls=GoogleFeeder, parser_cls=GoogleParser, downloader_cls=MyDownloader, prefix=\"\", *args, **kwargs):\n        super().__init__(feeder_cls, parser_cls, downloader_cls, *args, **kwargs)\n        self.downloader.prefix = prefix\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:09:03.776310Z\",\"iopub.execute_input\":\"2025-09-25T17:09:03.776535Z\",\"iopub.status.idle\":\"2025-09-25T17:09:03.796805Z\",\"shell.execute_reply.started\":\"2025-09-25T17:09:03.776509Z\",\"shell.execute_reply\":\"2025-09-25T17:09:03.796131Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# Function to search and download images \ndef search_images(term, max_images=400, folder_name=\".\"):\n    print(f\"Searching for '{term}'\")\n    crawler = MyCrawler(prefix=term, storage={'root_dir': folder_name})\n    crawler.crawl(keyword=term, max_num=max_images)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:09:03.797545Z\",\"iopub.execute_input\":\"2025-09-25T17:09:03.797773Z\",\"iopub.status.idle\":\"2025-09-25T17:10:38.836927Z\",\"shell.execute_reply.started\":\"2025-09-25T17:09:03.797756Z\",\"shell.execute_reply\":\"2025-09-25T17:10:38.836312Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# Download dataset for multiple categories \ndataset_path = Path('dataset')\ncategories = ('multirotor uav', 'fixed wing uav')\nimages_per_search = 400\n\nfor i in categories:\n    dest = dataset_path / i\n    dest.mkdir(exist_ok=True, parents=True)\n    search_images(f\"{i} photo\", images_per_search, dest)\n    sleep(5)\n    print(f\"Downloaded images for {i}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:10:38.837676Z\",\"iopub.execute_input\":\"2025-09-25T17:10:38.837883Z\",\"iopub.status.idle\":\"2025-09-25T17:11:04.940068Z\",\"shell.execute_reply.started\":\"2025-09-25T17:10:38.837856Z\",\"shell.execute_reply\":\"2025-09-25T17:11:04.939121Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nfrom PIL import Image, ImageFile\nfrom fastai.vision.all import resize_images\n\nImageFile.LOAD_TRUNCATED_IMAGES = True  # let Pillow load partially corrupted files\n\ndataset_path = Path('dataset')\n\nbad = []\n\n# 1) Convert all to RGB, overwrite in place\nfor img_path in dataset_path.rglob(\"*.*\"):\n    try:\n        with Image.open(img_path) as im:\n            if im.mode != \"RGB\":\n                im = im.convert(\"RGB\")\n            im.save(img_path)\n    except Exception:\n        bad.append(img_path)\n\n# 2) Delete files that still failed\nfor p in bad:\n    try: p.unlink()\n    except FileNotFoundError: pass\nprint(f\"Removed {len(bad)} corrupted images.\")\n\n# 3) Resize to max 400px\nresize_images(dataset_path, max_size=400, dest=dataset_path, recurse=True)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:11:04.941159Z\",\"iopub.execute_input\":\"2025-09-25T17:11:04.941456Z\",\"iopub.status.idle\":\"2025-09-25T17:11:05.268783Z\",\"shell.execute_reply.started\":\"2025-09-25T17:11:04.941426Z\",\"shell.execute_reply\":\"2025-09-25T17:11:05.268046Z\"}}\n# Remove corrupted images from dataset \nfailed = verify_images(get_image_files(dataset_path))\nfailed.map(Path.unlink)\nprint(f\"Removed {len(failed)} corrupted images.\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:11:05.271144Z\",\"iopub.execute_input\":\"2025-09-25T17:11:05.271413Z\",\"iopub.status.idle\":\"2025-09-25T17:11:05.277010Z\",\"shell.execute_reply.started\":\"2025-09-25T17:11:05.271388Z\",\"shell.execute_reply\":\"2025-09-25T17:11:05.276418Z\"}}\n# Verify final dataset structure \nfor folder in dataset_path.iterdir():\n    print(folder.name, len(list(folder.glob('*'))), \"images\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:11:05.277766Z\",\"iopub.execute_input\":\"2025-09-25T17:11:05.277943Z\",\"iopub.status.idle\":\"2025-09-25T17:11:05.293067Z\",\"shell.execute_reply.started\":\"2025-09-25T17:11:05.277928Z\",\"shell.execute_reply\":\"2025-09-25T17:11:05.292392Z\"}}\n# Remove unwanted categories if present (optional)\nunwanted_classes = ['airplane']\nfor cls in unwanted_classes:\n    folder = dataset_path / cls\n    if folder.exists():\n        shutil.rmtree(folder)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:11:05.294002Z\",\"iopub.execute_input\":\"2025-09-25T17:11:05.294273Z\",\"iopub.status.idle\":\"2025-09-25T17:11:06.746865Z\",\"shell.execute_reply.started\":\"2025-09-25T17:11:05.294245Z\",\"shell.execute_reply\":\"2025-09-25T17:11:06.745825Z\"}}\n# Create DataLoaders for training \ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='pad')]\n).dataloaders(dataset_path, bs=32)\n\ndls.show_batch(max_n=12)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:11:06.747765Z\",\"iopub.execute_input\":\"2025-09-25T17:11:06.747990Z\",\"iopub.status.idle\":\"2025-09-25T17:11:17.802013Z\",\"shell.execute_reply.started\":\"2025-09-25T17:11:06.747973Z\",\"shell.execute_reply\":\"2025-09-25T17:11:17.801267Z\"}}\n# Build an image classification model (defined with pretrained weights)\nlearn = vision_learner(dls, resnet34, metrics=error_rate)    \n\n# Train the model for 10 epochs\nlearn.fine_tune(10)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:11:17.803098Z\",\"iopub.execute_input\":\"2025-09-25T17:11:17.803428Z\",\"iopub.status.idle\":\"2025-09-25T17:11:18.426995Z\",\"shell.execute_reply.started\":\"2025-09-25T17:11:17.803401Z\",\"shell.execute_reply\":\"2025-09-25T17:11:18.426233Z\"}}\n# Classify a new image using the trained model \n# Grab one sample from the validation set\nimport random\nimport matplotlib.pyplot as plt\n\nidxs = random.sample(range(len(dls.valid_ds)), k=min(5, len(dls.valid_ds)))\n\nfor i in idxs:\n    img, true_lbl = dls.valid_ds[i]\n    pred_lbl, pred_idx, probs = learn.predict(img)\n\n    # Show image with labels in the title\n    img.show(figsize=(3,3), title=f\"True: {true_lbl} | Pred: {pred_lbl} ({probs[pred_idx]:.2f})\")\n\n    # Print detailed probabilities\n    print(f\"[{i}] True: {true_lbl} | Pred: {pred_lbl} | p={probs[pred_idx]:.3f}\")\n    for cls, p in zip(dls.vocab, probs):\n        print(f\"  {cls}: {p:.4f}\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-09-25T17:11:18.427859Z\",\"iopub.execute_input\":\"2025-09-25T17:11:18.428079Z\",\"iopub.status.idle\":\"2025-09-25T17:11:18.592606Z\",\"shell.execute_reply.started\":\"2025-09-25T17:11:18.428064Z\",\"shell.execute_reply\":\"2025-09-25T17:11:18.591724Z\"}}\n# Export the trained model \nlearn.export('uav_classification_model.pkl')","metadata":{"_uuid":"68276034-196d-4396-b547-7ce9fa3d4b54","_cell_guid":"56bd4989-0128-4a86-ba54-e373140f748e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}